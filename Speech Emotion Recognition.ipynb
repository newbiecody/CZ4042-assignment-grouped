{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaad494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "# tensorflow libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Conv1D\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# sklearn libraries are useful for preprocessing, performance measures, etc.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abd5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/'\n",
    "dir = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da27bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.DataFrame()\n",
    "count = 0\n",
    "for file in dir:\n",
    "    if file[-4:] == '.csv':\n",
    "        df_current_file = pd.read_csv(f'{path}\\\\{file}')\n",
    "        number_of_rows = len(df_current_file.index)\n",
    "        labels = [f'{file[:-4]}' for x in range(number_of_rows)]\n",
    "        df_current_file['label'] = labels\n",
    "        if count == 0:\n",
    "            df_combined = df_current_file\n",
    "        else:\n",
    "            df_combined = pd.concat([df_combined, df_current_file])\n",
    "        count += 1\n",
    "df_combined = df_combined.drop(axis=1, columns = ['file', 'start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e37e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, test_size, random_state):\n",
    "\n",
    "    # Encode the labels from 0 to n_classes-1  \n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "  \n",
    "    # devide data to train and test\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state = random_state)\n",
    "    \n",
    "    # scale the training inputs\n",
    "    x_train = df_train.drop(axis = 1, columns = ['label'])\n",
    "    y_train = df_train['label'].to_numpy()\n",
    "    \n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    x_train_scaled = standard_scaler.fit_transform(x_train)\n",
    "\n",
    "    #scale and prepare testing data\n",
    "    x_test = df_test.drop(axis = 1, columns = ['label'])\n",
    "    x_test_scaled = standard_scaler.transform(x_test)\n",
    "    y_test = df_test['label'].to_numpy() \n",
    "  \n",
    "    return x_train_scaled, y_train, x_test_scaled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b65417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 988) (1008,)\n",
      "(432, 988) (432,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_dataset(df_combined, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bc8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(988),\n",
    "    Dropout(0.5),\n",
    "    Dense(663, activation = 'relu'),\n",
    "    Dense(442, activation = 'relu'),\n",
    "    Dense(8, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d925ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1008/1008 - 5s - loss: 2.0450 - accuracy: 0.3720 - val_loss: 1.6422 - val_accuracy: 0.4375\n",
      "Epoch 2/50\n",
      "1008/1008 - 5s - loss: 1.4419 - accuracy: 0.5308 - val_loss: 1.3211 - val_accuracy: 0.5440\n",
      "Epoch 3/50\n",
      "1008/1008 - 5s - loss: 1.1322 - accuracy: 0.6071 - val_loss: 1.5977 - val_accuracy: 0.5347\n",
      "Epoch 4/50\n",
      "1008/1008 - 4s - loss: 1.0187 - accuracy: 0.6766 - val_loss: 2.3453 - val_accuracy: 0.4560\n",
      "Epoch 5/50\n",
      "1008/1008 - 4s - loss: 0.9838 - accuracy: 0.6786 - val_loss: 1.7471 - val_accuracy: 0.5579\n",
      "Epoch 6/50\n",
      "1008/1008 - 5s - loss: 0.9460 - accuracy: 0.6964 - val_loss: 1.4800 - val_accuracy: 0.6019\n",
      "Epoch 7/50\n",
      "1008/1008 - 5s - loss: 0.8530 - accuracy: 0.7321 - val_loss: 1.4541 - val_accuracy: 0.5787\n",
      "Epoch 8/50\n",
      "1008/1008 - 5s - loss: 0.8322 - accuracy: 0.7708 - val_loss: 1.6787 - val_accuracy: 0.5833\n",
      "Epoch 9/50\n",
      "1008/1008 - 5s - loss: 0.7526 - accuracy: 0.7758 - val_loss: 2.0999 - val_accuracy: 0.5764\n",
      "Epoch 10/50\n",
      "1008/1008 - 5s - loss: 0.7667 - accuracy: 0.7897 - val_loss: 1.9823 - val_accuracy: 0.5509\n",
      "Epoch 11/50\n",
      "1008/1008 - 4s - loss: 0.7743 - accuracy: 0.8036 - val_loss: 2.2136 - val_accuracy: 0.6111\n",
      "Epoch 12/50\n",
      "1008/1008 - 5s - loss: 0.7026 - accuracy: 0.8065 - val_loss: 1.7792 - val_accuracy: 0.6389\n",
      "Epoch 13/50\n",
      "1008/1008 - 5s - loss: 0.6243 - accuracy: 0.8224 - val_loss: 2.0054 - val_accuracy: 0.6111\n",
      "Epoch 14/50\n",
      "1008/1008 - 5s - loss: 0.5878 - accuracy: 0.8383 - val_loss: 1.9069 - val_accuracy: 0.5880\n",
      "Epoch 15/50\n",
      "1008/1008 - 5s - loss: 0.5921 - accuracy: 0.8194 - val_loss: 2.3059 - val_accuracy: 0.5787\n",
      "Epoch 16/50\n",
      "1008/1008 - 5s - loss: 0.4654 - accuracy: 0.8562 - val_loss: 2.2918 - val_accuracy: 0.6227\n",
      "Epoch 17/50\n",
      "1008/1008 - 5s - loss: 0.7096 - accuracy: 0.8393 - val_loss: 1.9200 - val_accuracy: 0.6366\n",
      "Epoch 18/50\n",
      "1008/1008 - 5s - loss: 0.5839 - accuracy: 0.8601 - val_loss: 2.3224 - val_accuracy: 0.5903\n",
      "Epoch 19/50\n",
      "1008/1008 - 5s - loss: 0.5843 - accuracy: 0.8651 - val_loss: 2.1519 - val_accuracy: 0.6412\n",
      "Epoch 20/50\n",
      "1008/1008 - 5s - loss: 0.5166 - accuracy: 0.8661 - val_loss: 2.8019 - val_accuracy: 0.5972\n",
      "Epoch 21/50\n",
      "1008/1008 - 5s - loss: 0.6349 - accuracy: 0.8671 - val_loss: 2.8038 - val_accuracy: 0.5972\n",
      "Epoch 22/50\n",
      "1008/1008 - 5s - loss: 0.6090 - accuracy: 0.8651 - val_loss: 2.6721 - val_accuracy: 0.5995\n",
      "Epoch 23/50\n",
      "1008/1008 - 5s - loss: 0.5256 - accuracy: 0.8730 - val_loss: 2.4300 - val_accuracy: 0.6181\n",
      "Epoch 24/50\n",
      "1008/1008 - 5s - loss: 0.6911 - accuracy: 0.8552 - val_loss: 2.4802 - val_accuracy: 0.6065\n",
      "Epoch 25/50\n",
      "1008/1008 - 5s - loss: 0.4506 - accuracy: 0.8938 - val_loss: 2.9990 - val_accuracy: 0.6366\n",
      "Epoch 26/50\n",
      "1008/1008 - 5s - loss: 0.5803 - accuracy: 0.8819 - val_loss: 3.7242 - val_accuracy: 0.5810\n",
      "Epoch 27/50\n",
      "1008/1008 - 5s - loss: 0.5180 - accuracy: 0.8859 - val_loss: 2.8456 - val_accuracy: 0.6366\n",
      "Epoch 28/50\n",
      "1008/1008 - 5s - loss: 0.4347 - accuracy: 0.9077 - val_loss: 3.0347 - val_accuracy: 0.6412\n",
      "Epoch 29/50\n",
      "1008/1008 - 5s - loss: 0.5177 - accuracy: 0.8988 - val_loss: 3.2452 - val_accuracy: 0.6111\n",
      "Epoch 30/50\n",
      "1008/1008 - 5s - loss: 0.3911 - accuracy: 0.9206 - val_loss: 3.6143 - val_accuracy: 0.6227\n",
      "Epoch 31/50\n",
      "1008/1008 - 5s - loss: 0.5737 - accuracy: 0.8988 - val_loss: 2.6738 - val_accuracy: 0.6690\n",
      "Epoch 32/50\n",
      "1008/1008 - 5s - loss: 0.3841 - accuracy: 0.9196 - val_loss: 2.9696 - val_accuracy: 0.6412\n",
      "Epoch 33/50\n",
      "1008/1008 - 5s - loss: 0.5399 - accuracy: 0.8909 - val_loss: 2.8427 - val_accuracy: 0.6620\n",
      "Epoch 34/50\n",
      "1008/1008 - 5s - loss: 0.5950 - accuracy: 0.8998 - val_loss: 3.8257 - val_accuracy: 0.6204\n",
      "Epoch 35/50\n",
      "1008/1008 - 5s - loss: 0.4116 - accuracy: 0.9127 - val_loss: 2.8987 - val_accuracy: 0.6366\n",
      "Epoch 36/50\n"
     ]
    }
   ],
   "source": [
    "batchSize = 1\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = batchSize,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 2,\n",
    "                    use_multiprocessing = True,\n",
    "                    validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('No. of epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot([x for x in range(0,50)], model.history.history['accuracy'], label = 'Train data')\n",
    "plt.plot([x for x in range(0,50)], model.history.history['val_accuracy'], label = 'Test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a5075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
